## Model Tuning

 We are working towards our own improved version of GPT-J for snippet generation.
 
 Currently, we evaluate the following approaches for model tuning:
 
 - Classic model [fine tuning](https://github.com/snipaid-nlg/model-tuning/blob/main/GPT-J-6B-8bit-HeadlineGeneration.ipynb)
 - Multitask fine tuning
 - [Prompt tuning](https://github.com/snipaid-nlg/model-tuning/blob/main/GPT-J-6B-8bit-HeadlineGeneration.ipynb)
 
 ### Results
 
Prompt tuning does not prove to be successfull. \
Fine tuning and multitask fine tuning seem promising.
